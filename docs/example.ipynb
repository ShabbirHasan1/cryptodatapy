{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fdc7d8c",
   "metadata": {},
   "source": [
    "# CryptoDataPy \n",
    "\n",
    "`v0.0.1` \n",
    "\n",
    "Last Updated: 2022-09-22\n",
    "\n",
    "**CryptoDataPy** allows you to create high quality data sets ready for analysis from a variety of sources with only a few lines of code. The easy to use interface facilitates each step of the ETL (extract-transform-load) process, saving you time and effort from having to spend countless hours studying documentation, extracting data from different file formats and sources, as well as wrangling and cleaning the data.\n",
    "\n",
    "In this notebook, we will walk through how to use **CryptoDataPy** to query various types of data from multiple sources and get it ready for data analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3243eebb",
   "metadata": {},
   "source": [
    "\n",
    "## Table of Contents:\n",
    "### Use Cases:\n",
    "- [Long/short strategies](#long-short): collect perpetual futures prices for long/short algo trading strategy development, and extend sample history back using aggregate exchange spot prices.\n",
    "- [Data cleaning](#data-cleaning): clean on-chain data in a few lines of code.\n",
    "- [Stablecoin analysis](#stablecoins): get key indicators for the largest stablecoins.\n",
    "\n",
    "\n",
    "### Objects:\n",
    "- [Data Catalog](#data-catalog): `DataCatalog` allows you to **explore what data is available** and understand it better.\n",
    "- [Data Request](#data-request): `DataRequest` provides an intuitive parameter interface which allows you to **specify the parameter values** for the data you want.\n",
    "- [Get Data](#get-data): `GetData` **retrieves either metadata or time series data** from the data source for the parameters specified in the data request. \n",
    "- [Clean Data](#clean-data): `CleanData` provides **tools for data cleaning** including: filtering and repairing outliers, filtering assets trading below an average traded value (liquidity), removing observations with long periods of missing values, removing tickers with short price histories (minimum number of observations), and removing specific tickers to be excluded from the analysis (e.g. stablecoins)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebad8633",
   "metadata": {},
   "source": [
    "# Long/Short Strategies <a class=\"anchor\" id=\"long-short\"></a>\n",
    "\n",
    "Let's collect market and funding rate data for long/short algo trading strategy research. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019f594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc04c34e",
   "metadata": {},
   "source": [
    "## Step 1: Define Asset Universe\n",
    "\n",
    "\n",
    "Let's start by collecting our data.\n",
    "\n",
    "First, we need to import `DataRequest` and `GetData` and select a data source to pull metadata from it using the `get_asset_info` method.\n",
    "\n",
    "This will allow us to create a tickers list for our asset universe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a801ec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cryptodatapy.extract.datarequest import DataRequest\n",
    "from cryptodatapy.extract.getdata import GetData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce41a528",
   "metadata": {},
   "source": [
    "Let's get a list of tickers for the universe of assets with perpetual futures contracts trading on binance, the most liquid cryptoasset exchange."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d79b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_req = DataRequest(source='ccxt')\n",
    "perp_tickers = GetData(data_req).get_meta(method='get_markets_info', exch='binanceusdm', as_list=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984c91dd",
   "metadata": {},
   "source": [
    "Which gives us an asset universe of 150 + cryptoassets to trade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfaab03",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(perp_tickers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fedf46",
   "metadata": {},
   "source": [
    "## Step 2: Get Perpetual Futures Data\n",
    "\n",
    "\n",
    "Next, let's create a data request for both market prices and funding rates for those perpetual futures tickers, using only the first 10 tickers for illustrative purposes.\n",
    "\n",
    "**Note**: using the `source_tickers` parameter is recommended when the tickers are already in the data source's format. If data source's format is not known, CryptoDataPy will convert tickers to source tickers automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9de9dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_req = DataRequest(source='ccxt',\n",
    "                       source_tickers=perp_tickers[:10], \n",
    "                       fields=['close', 'volume', 'funding_rate'], \n",
    "                       mkt_type='perpetual_future', \n",
    "                       freq='d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d272b2e",
   "metadata": {},
   "source": [
    "We can now retrieve this data request using the `GetData` object and the `get_series` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ae249a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = GetData(data_req).get_series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365ae5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082f7fa9",
   "metadata": {},
   "source": [
    "## Step 3: Extend Sample Size with Spot Data\n",
    "\n",
    "Since perpetual futures only started trading in 2019 on Binance, this gives us a limited sample size for quantitative research. Let's extend it back using spot prices from another data source.\n",
    "\n",
    "We will need to replace the market tickers with base asset tickers first from aggregate exchange prices on CryptoCompare before pulling the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d76223",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_tickers = [ticker.split('/')[0] for ticker in perp_tickers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b428beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_req = DataRequest(source='cryptocompare',\n",
    "                       tickers=cc_tickers[:10], \n",
    "                       fields=['close', 'volume'], \n",
    "                       mkt_type='spot', \n",
    "                       freq='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209812fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = GetData(data_req).get_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01dc951",
   "metadata": {},
   "source": [
    "We can now combine the two datasets to extend our history back to 2010."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f069ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.unstack().combine_first(df1.unstack()).stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876fbf6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8489c48",
   "metadata": {},
   "source": [
    "## Step 4: Filter Asset Universe\n",
    "\n",
    "Lastly, we may want to filter this asset universe by:\n",
    "\n",
    "- identifying and repairing outliers\n",
    "- removing low trading volume cryptoassets (< $10 mil USD average traded volume)\n",
    "- removing cryptoassets with a limited data history (< 100 observations)\n",
    "\n",
    "We will need to import `CleanData` to use the filter methods available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf805af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import CleanData \n",
    "from cryptodatapy.transform.clean import CleanData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701a1630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data\n",
    "clean_df = CleanData(df).filter_outliers(od_method='mad').\\\n",
    "                         repair_outliers(imp_method='interpolate').\\\n",
    "                         filter_avg_trading_val(thresh_val=10000000).\\\n",
    "                         filter_missing_vals_gaps().\\\n",
    "                         filter_min_nobs().get(attr='df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ffa28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.dropna(how='all').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fa47f6",
   "metadata": {},
   "source": [
    "We have extended our data sample by an extra 5 years and are now ready to do some long/short algo trading strategy research!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12231d54",
   "metadata": {},
   "source": [
    "# Data Cleaning <a class=\"anchor\" id=\"data-cleaning\"></a>\n",
    "\n",
    "Cryptoassets create a lot of data, but the data can have a lot of outliers and irregularities that can wreak havoc with predictive/ML models down stream. This is especially true for on-chain data and off-chain data, as well as higher frequency market data.\n",
    "\n",
    "This makes data cleaning and important part of any high quality cryptoasset data pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbb5166",
   "metadata": {},
   "source": [
    "## Step 1: Data Extraction\n",
    "\n",
    "\n",
    "Let's start by collecting our data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cdfe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# glassnode\n",
    "data_req = DataRequest(source='glassnode', \n",
    "                       tickers=['btc', 'eth'], \n",
    "                       fields=['close', 'add_act', 'hashrate'], \n",
    "                       freq='d',\n",
    "                      start_date='2016-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825763be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = GetData(data_req).get_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01824fa",
   "metadata": {},
   "source": [
    "With same data request parameters, can you retrieve the same data from other sources for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3941448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coinmetrics\n",
    "data_req = DataRequest(source='coinmetrics', \n",
    "                       tickers=['btc', 'eth'], \n",
    "                       fields=['close', 'add_act', 'hashrate'], \n",
    "                       freq='d',\n",
    "                      start_date='2016-01-01')\n",
    "df1 = GetData(data_req).get_series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866febd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cryptocompare\n",
    "data_req = DataRequest(source='cryptocompare', \n",
    "                       tickers=['btc', 'eth'], \n",
    "                       fields=['close', 'add_act', 'hashrate'], \n",
    "                       freq='d',\n",
    "                      start_date='2016-01-01')\n",
    "df2 = GetData(data_req).get_series()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0d4ed1",
   "metadata": {},
   "source": [
    "## Step 2: Visual Data Inspection\n",
    "\n",
    "Next, we can plot the series from various sources to compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c3c13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat dfs\n",
    "df3 = pd.concat([df, df1, df2], axis=1)\n",
    "add_act_df = df3.loc[pd.IndexSlice[:, 'ETH'], 'add_act'].droplevel(1)\n",
    "# rename cols\n",
    "col_names = [vendor + '_' + 'ETH_' + 'active_addresses' for vendor in ['glassnode', 'coinmetrics', 'cryptocompare']]\n",
    "add_act_df.columns = col_names\n",
    "# plot active addresses\n",
    "add_act_df.plot(figsize=(15,5))\n",
    "add_act_df.loc['2016-09-01':'2017-01-01'].plot(figsize=(15,5))\n",
    "add_act_df.plot(subplots=True, layout=(1,3), figsize=(15,5))\n",
    "plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658be29c",
   "metadata": {},
   "source": [
    "Comparing the three active address series, we notice that both the Cryptocompare and Coinmetrics active addresses appear to have **large outliers in ETH active addresses** in late 2016. \n",
    "\n",
    "Large outliers can cause major distortions down stream in any machine learning or predictive process so cleaning this data before doing so is a necessary next step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50b06be",
   "metadata": {},
   "source": [
    "## Step 3: Data Cleaning\n",
    "\n",
    "Once outliers are detected through visual data inspection, they can be filtered and repaired by importing **CryptoDataPy**'s `CleanData` module. \n",
    "\n",
    "We have several options:\n",
    "\n",
    "1. **Use the series without large outliers**.\n",
    "2. **Filter the outliers using one of CryptoDataPy's outlier detection methods** (shown below) and keeping the 'clean' series.\n",
    "3. **Combine 1 and 2**, e.g. filtering and repairing outliers using outlier detection and missing values imputation algorithms, and then taking the median (or some other measure of central tendency) from the resulting series as the representative 'true series'(also shown below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1d8182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import CleanData module\n",
    "from cryptodatapy.transform.clean import CleanData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d31b41",
   "metadata": {},
   "source": [
    "Here, we will use the **STL outlier detection algorithm**, similar to the one used by [Twitter](https://blog.twitter.com/engineering/en_us/a/2015/introducing-practical-and-robust-anomaly-detection-in-a-time-series) to filter/remove outliers, and then use the **interpolation method** for repair of bad data/missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fed3be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter coinmetrics data \n",
    "# show raw vs filtered plot\n",
    "CleanData(df1).filter_outliers(od_method='stl').repair_outliers(imp_method='interpolate').show_plot(plot_series=('ETH', 'add_act'))\n",
    "# save filtered df\n",
    "clean_df1 = CleanData(df1).filter_outliers(od_method='stl').repair_outliers(imp_method='interpolate').get(attr='df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c6b28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter cryptocompare data \n",
    "# show raw vs filtered plot\n",
    "CleanData(df2).filter_outliers(od_method='stl').repair_outliers(imp_method='interpolate').show_plot(plot_series=('ETH', 'add_act'))\n",
    "# save filtered df\n",
    "clean_df2 = CleanData(df2).filter_outliers(od_method='stl').repair_outliers(imp_method='interpolate').get(attr='df')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acf59fe",
   "metadata": {},
   "source": [
    "Let's visually inspect the data once again to assess data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c853187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat dfs\n",
    "df_clean = pd.concat([df, clean_df1, clean_df2], axis=1)\n",
    "add_act_df1 = df_clean.loc[pd.IndexSlice[:, 'ETH'], 'add_act'].droplevel(1)\n",
    "# rename cols\n",
    "col_names = [vendor + '_' + 'ETH_' + 'active_addresses' for vendor in ['glassnode', 'coinmetrics', 'cryptocompare']]\n",
    "add_act_df1.columns = col_names\n",
    "# plot active addresses\n",
    "add_act_df1.plot(figsize=(15,5))\n",
    "add_act_df1.loc['2016-09-01':'2017-01-01'].plot(figsize=(15,5))\n",
    "add_act_df1.plot(subplots=True, layout=(1,3), figsize=(15,5))\n",
    "plt.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1d6c05",
   "metadata": {},
   "source": [
    "These data cleaning algorithms do a good job of filtering and repairing large outliers as we can see.\n",
    "\n",
    "We can now use one of the 'cleaned' data sets for data analysis, or alternatively, **use all 3 series to construct a 'series of truth'** which uses the median of the 3 time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6d130c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot series of truth\n",
    "df_clean.add_act.median(axis=1).unstack()['ETH'].plot(title='ETH Active Addresses - Series of Truth', figsize=(15,7));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27da44ec",
   "metadata": {},
   "source": [
    "You are now ready to begin exploring, analyzing and predicting with clean data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17e9a17",
   "metadata": {},
   "source": [
    "# Stablecoin Analysis <a class=\"anchor\" id=\"stablecoins\"></a>\n",
    "\n",
    "Stablecoins are a growing and import part of the cryptoeconomic ecosystem. The recent failures of some stablecoin projects and the broader impact this can have on the ecosystem makes risk monitoring and analysis of stablecoins increasingly import.\n",
    "\n",
    "**CrptoDataPy** makes it easy to find data on stablecoins.\n",
    "\n",
    "The `DataCatalog` allows us to find information on the largest stablecoins by market cap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6a3228",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cryptodatapy.util.datacatalog import DataCatalog \n",
    "dc = DataCatalog()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c199c2",
   "metadata": {},
   "source": [
    "If we want to get metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1ad7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_meta = dc.get_tickers_metadata(cat='crypto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc2d338",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_meta.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842e295b",
   "metadata": {},
   "source": [
    "Or we can get a list of stablecoins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88886520",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_list = dc.get_tickers_metadata(cat='crypto', as_list=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ed544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c36b80",
   "metadata": {},
   "source": [
    "If instead we want an updated stablecoin list, we can use the `scrape_stablecoins` method to scrape stablecoin information for various source. The information will be returned to us sorted by market cap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b302901",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_scraped = dc.scrape_stablecoins(source='coinmarketcap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7d5704",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_scraped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6d6e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_sc_list = sc_scraped.index.to_list()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92120299",
   "metadata": {},
   "source": [
    "We can take the top 5 stablecoins by market cap and we can find out which ones have available data selecting from a specific source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb7a1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_assets = GetData(DataRequest(source='coinmetrics')).get_meta(attr='assets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ea62d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_sc_list = [asset for asset in cm_assets if asset.upper() in top_sc_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f418443a",
   "metadata": {},
   "source": [
    "Coinmetrics provides data on all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc542a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cm_sc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd21a34",
   "metadata": {},
   "source": [
    "We can then narrow it down further to the assets with circulating supply data, a key metric for stablecoin health."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb82527d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_req = DataRequest(source='coinmetrics', tickers=cm_sc_list, fields=['supply_circ', 'ref_rate_usd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fe8b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_supply_list = GetData(data_req).get_meta(method='get_onchain_tickers_list', data_req=data_req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121c2d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_sc_list = [asset for asset in cm_supply_list if asset.upper() in top_sc_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29633ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_sc_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0a49e2",
   "metadata": {},
   "source": [
    "Finally, we can pull circulationg supply for those stablecoins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f1da90",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_req = DataRequest(source='coinmetrics', tickers=cm_sc_list, fields=['supply_circ', 'ref_rate_usd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39035ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = GetData(data_req).get_series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978301c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32802976",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.unstack().supply_circ.plot(title='Stablecoins - Circulating Supply', figsize=(15,7));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db747ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.unstack().ref_rate_usd.plot(title='Stablecoins - Price', figsize=(15,7));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7410b08c",
   "metadata": {},
   "source": [
    "You are now ready to monitor key indicators for stablecoins!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4ad689",
   "metadata": {},
   "source": [
    "For a deeper dive on how to maximize your use of **CryptoDataPy**, we explore how to use each one of it's objects below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568c9b75",
   "metadata": {},
   "source": [
    "# Data Catalog <a class=\"anchor\" id=\"data-catalog\"></a>\n",
    "\n",
    "The `DataCatalog` allow us to explore what data is available and understand it better.\n",
    "\n",
    "It includes the following attributes and methods:\n",
    "\n",
    "- [Data sources](#data-sources): the `data_sources` attribute retrieves information on all the available data sources. \n",
    "- [Metadata](#metadata): the `get_tickers_metadata` method retrieves information on available tickers. The `get_fields_metadata` method retrieves information on available fields. \n",
    "- [Search](#search): the `search_tickers` method allows you to search for tickers by ticker, country, country id, asset class, etc. The `search_fields` method allows you to search for fields by name, id, category, etc. It also provides identifiers for each data source.\n",
    "- [Stablecoins](#stablecoins): the `scrape_stablecoins` method scrapes information on stablecoins from the selected source. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d711562a",
   "metadata": {},
   "source": [
    "To access the data catalog, instantiate a DataCatalog object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de02ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cryptodatapy.util.datacatalog import DataCatalog \n",
    "dc = DataCatalog()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990d8359",
   "metadata": {},
   "source": [
    "### Data Sources <a class=\"anchor\" id=\"data-sources\"></a>\n",
    "\n",
    "Available `data sources` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cba2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.data_sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a8bfb4",
   "metadata": {},
   "source": [
    "### Metadata<a class=\"anchor\" id=\"metadata\"></a>\n",
    "\n",
    "Available tickers can be accessed with the `get_tickers_metadata` method.\n",
    "\n",
    "**Note**: cryptoasset and individual equity tickers are not listed in the tickers metadata due to a large number of assets. They can be accessed by calling the data source object and using the `get_assets_info` method to see available tickers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f631b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.get_tickers_metadata().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b334953",
   "metadata": {},
   "source": [
    "Available fields can be accessed with the `get_fields_metadata` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a8f825",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.get_fields_metadata().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5b81ba",
   "metadata": {},
   "source": [
    "### Search <a class=\"anchor\" id=\"search\"></a>\n",
    "\n",
    "We can search for tickers with the `search_tickers` method by column name and keyword.\n",
    "\n",
    "Let's look for tickers with assets in the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e5e564",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.search_tickers(by_col='country_id_2', keyword='US').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d0acdc",
   "metadata": {},
   "source": [
    "The same can be done when searching for fields.\n",
    "\n",
    "For example, let's look for avaialble on-chain data fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ebd25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.search_fields(by_col='category', keyword='on-chain').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7218bd63",
   "metadata": {},
   "source": [
    "### Stablecoins<a class=\"anchor\" id=\"stablecoins\"></a>\n",
    "\n",
    "We can find static info on stablecoins by using the `get_tickers_metadata` method and setting the `cat` parameter to 'crypto' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e386184",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.get_tickers_metadata(cat='crypto').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19093c06",
   "metadata": {},
   "source": [
    "For dynamic/real-time info on stablecoins, we can scrape the data from CoinGecko or CoinMarketCap using the `scrape_stablecoins` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64abab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "dc.scrape_stablecoins(source='coinmarketcap').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4510ef13",
   "metadata": {},
   "source": [
    "# Data Request <a class=\"anchor\" id=\"data-request\"></a>\n",
    "\n",
    "`DataRequest` provides an intuitive parameter interface which allows you to **specify the parameter values** for the data you want.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91507eb9",
   "metadata": {},
   "source": [
    "By initializing a `DataRequest` object, we provide all the relevant parameters needed to retrieve data from the selected data source. `DataRequest` will automatically convert parameter values to the format required for each data source, allowing the user to experience a consistent and intuitive interface for every data source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7deafdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_req = DataRequest(\n",
    "    source='cryptocompare',  # provide the name of the supported data source, if not specified defaults to 'CCXT'\n",
    "    tickers=['btc', 'eth'],  # ticker symbols, if not specified defaults to 'btc'\n",
    "    freq = 'd',  # frequency of data, if not specified defaults to daily\n",
    "    quote_ccy = 'USDT',  # quote currency, if not specified defaults to USD/USDT\n",
    "    exch = None,  # exchance, if not specified defaults to aggregate \n",
    "    mkt_type = \"spot\",  # market type, if not specified defaults to spot\n",
    "    start_date = None,  # start date, if not specified defaults to beginning of data history\n",
    "    end_date = None,  # end date, if not specified defaults to end of data history\n",
    "    fields = [\"close\", 'volume', \"add_act\"],  # data fields, if not specified defaults to close\n",
    "    tz = None,  # timezone, if not specified defaults to 'UTC'\n",
    "    inst = None,  # institution name, only necessary when retrieving data from institution, e.g. grayscale\n",
    "    cat = None,  # category of asset or data, must be specified when data source provides data for many asset classes\n",
    "    trials = 3,  # number of tries when requesting data, defaults to 3 \n",
    "    pause = 0.1,  # pause between trials to avoid rate limits, defaults to 0.1 sec\n",
    "    source_tickers = None,  # tickers in data source format, overrides tickers parameter when specified \n",
    "    source_freq = None,  # frequency in data source format, overrides tickers parameter when specified \n",
    "    source_fields = None,  # fields in data source format, overrides tickers parameter when specified \n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee4062b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vars(data_req)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b08b1e2",
   "metadata": {},
   "source": [
    "# Get Data <a class=\"anchor\" id=\"get-data\"></a>\n",
    "\n",
    "`GetData` retrieves either metadata or time series data from the data source and parameters specified in the data request.\n",
    "\n",
    "- [Get meta](#get-meta): the `get_meta` method will instantiate a data source object for the selected data source and retrieve all the relevant metadata for it.\n",
    "-[Get series](#get-series): the `get_series` method will retrieve any time series data by initializing the selected data source's object and using the `get_data` method. The data is retrieved and wrangled into [tidy data](https://www.jstatsoft.org/article/view/v059i10) format.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e669fe2",
   "metadata": {},
   "source": [
    "### Get Meta  <a class=\"anchor\" id=\"get-meta\"></a>\n",
    "\n",
    "Using the `DataRequest` object we initialized in the previous section, we can get information on availalable assets by using the `get_meta` method and specifying the metadata method for the data source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6237ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "GetData(data_req).get_meta(method='get_assets_info').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066cfe8e",
   "metadata": {},
   "source": [
    "### Get Series  <a class=\"anchor\" id=\"get-series\"></a>\n",
    "\n",
    "We can then pull the time series data using the `get_series` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23aa182c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = GetData(data_req).get_series()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca6fbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b11923",
   "metadata": {},
   "source": [
    "# Clean Data <a class=\"anchor\" id=\"clean-data\"></a>\n",
    "\n",
    "`CleanData` provides **tools for data cleaning**. \n",
    "\n",
    "- [Outlier Detection](#od): the `OutlierDetection` class contains a range of method for outlier detection in time series data. Many traditional outlter detection method are not well suited for time series data.\n",
    "- [Filter](#filter): the `Filter` class contains methods that allow the filtering of unwanted values (e.g. below a trading liquidity threshold) and tickers (ticker with insufficient price history or stablecoins) to get the data ready for a specific type of analysis (e.g. long/short startegy research, on-chain predictive analytics, etc).\n",
    "- [Impute](#impute): the `Impute` class deals with missing values in the data with methods that will replace missing values, or repair outliers which were removed by an outlier detection algorithm.\n",
    "- [Clean Data](#clean-data): the `CleanData` class is composed of the previous three classes to allow the creation of a data cleaningn pipeline in a few lines of code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbe8164",
   "metadata": {},
   "source": [
    "### Outlier Detection <a class=\"anchor\" id=\"od\"></a>\n",
    "\n",
    "The `OutlierDetection` class has 8 methods which implement an outlier detection algorithm with the flexibility to set parameters according to use case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5481a47e",
   "metadata": {},
   "source": [
    "For example, we can use the `stl` outlier detection method to decompose series into three components: trend, seasonal and residual.\n",
    "\n",
    "We run it on the dataframe we retrieved in the previous section using the `filter_outliers` method and `show_plot` to show the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfac5c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CleanData(df).filter_outliers(od_method='stl', thresh_val=20).show_plot(plot_series=('ETH', 'add_act'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a3a733",
   "metadata": {},
   "source": [
    "We can see that it goes a reasonably good job of identifying the large global outliers in active addresses for ETH in late 2017."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7682992e",
   "metadata": {},
   "source": [
    "### Filter <a class=\"anchor\" id=\"filter\"></a>\n",
    "\n",
    "In addition to filtering outliers, the `Filter` class has several methods allow us to remove data that isn't of interest to us in our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73adf6be",
   "metadata": {},
   "source": [
    "For example, let's say we only want assets with a mimimum of $10 mil USD of average traded volumne, and those with a minimum of 100 price close observations. We can run the `filter_avg_trading_val` and `filter_min_nobs` methods on the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee4b74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CleanData(df).filter_avg_trading_val(thresh_val=10000000, window_size=30).filter_min_nobs(min_obs=100).show_plot(plot_series=('ETH', 'close'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b96405",
   "metadata": {},
   "source": [
    "We see that our filter removed values up to early 2017 since ETH didn't meet the minimum average trading value over a 30-day window."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3195cd6b",
   "metadata": {},
   "source": [
    "### Impute <a class=\"anchor\" id=\"impute\"></a>\n",
    "\n",
    "The `Impute` class has several methods that allow us to replace missing values which can cause many issues in predictive/ML models, e.g. scikit-learn and other ML packages may not like missing values and fail to run properly.\n",
    "\n",
    "We can use it to impute/repair the missing vals/outliers from late 2017 for ETH active addresses with the `repair_outliers` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49abd349",
   "metadata": {},
   "outputs": [],
   "source": [
    "CleanData(df).filter_outliers(od_method='stl').\\\n",
    "              repair_outliers(imp_method='interpolate').\\\n",
    "              show_plot(plot_series=('ETH', 'add_act'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e78e97",
   "metadata": {},
   "source": [
    "### Clean Data <a class=\"anchor\" id=\"clean-data\"></a>\n",
    "\n",
    "`CleanData` allows us to chain together a series of data cleaning operations and returns either a plot of the filtered vs. raw data, the clean data in a dataframe, the filtered outlies (and forecasts if applicable) and/or a summary of all the data cleaning operations and final data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398800e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CleanData(df).filter_outliers(od_method='stl').\\\n",
    "              repair_outliers(imp_method='interpolate').\\\n",
    "              filter_avg_trading_val(thresh_val=10000000).\\\n",
    "              get(attr='summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51698a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CleanData(df).filter_outliers(od_method='stl').\\\n",
    "              repair_outliers(imp_method='interpolate').\\\n",
    "              filter_avg_trading_val(thresh_val=10000000).\\\n",
    "              get(attr='df')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
