{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a197b250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from time import sleep\n",
    "from typing import Optional, Union\n",
    "from cryptodatapy.util.datacredentials import DataCredentials\n",
    "from cryptodatapy.util.convertparams import ConvertParams\n",
    "from cryptodatapy.data_vendors.datavendor import DataVendor\n",
    "from cryptodatapy.data_requests.datarequest import DataRequest\n",
    "\n",
    "# data credentials\n",
    "data_cred = DataCredentials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "316b5e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CryptoCompare(DataVendor):\n",
    "    \"\"\"\n",
    "    Retrieves data from CryptoCompare API.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            source_type: str = 'data_vendor',\n",
    "            categories: list[str] = ['crypto'],\n",
    "            assets: list[str] = None,\n",
    "            indexes: list[str] = None,\n",
    "            markets: list[str] = None,\n",
    "            market_types: list[str] = ['spot'],\n",
    "            fields: list[str] = None,\n",
    "            frequencies: list[str] = ['1min', '1h', 'd'],\n",
    "            exchanges: list[str] = None,\n",
    "            base_url: str = data_cred.cryptocompare_base_url,\n",
    "            api_key: str = data_cred.cryptocompare_api_key,\n",
    "            max_obs_per_call: int = 2000,\n",
    "            rate_limit: pd.DataFrame = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        source_type: str, {'data_vendor', 'exchange', 'library', 'on-chain', 'web'}\n",
    "            Type of data source, e.g. 'data_vendor'\n",
    "        categories: list[str], {'crypto', 'fx', 'rates', 'equities', 'commodities', 'credit', 'macro', 'alt'}\n",
    "            List of available categories, e.g. ['crypto', 'fx', 'alt']\n",
    "        assets: list[str]\n",
    "            List of available assets, e.g. ['btc', 'eth']\n",
    "        indexes: list[str]\n",
    "            List of available indexes, e.g. ['mvda', 'bvin']\n",
    "        markets: list[str]\n",
    "            List of available markets as asset/quote currency pairs, e.g. ['btcusdt', 'ethbtc']\n",
    "        market_types: list[str]\n",
    "            List of available market types/contracts, e.g. [spot', 'perpetual_futures', 'futures', 'options']\n",
    "        fields: list[str]\n",
    "            List of available fields, e.g. ['open', 'high', 'low', 'close', 'volume']\n",
    "        frequencies: list[str]\n",
    "            List of available frequencies, e.g. ['tick', '1min', '5min', '10min', '20min', '30min', '1h', '2h', '4h',\n",
    "            '8h', 'd', 'w', 'm']\n",
    "        exchanges: list[str]\n",
    "            List of available exchanges, e.g. ['Binance', 'Coinbase', 'Kraken', 'FTX']\n",
    "        base_url: str\n",
    "            Cryptocompare base url used in GET requests, e.g. 'https://min-api.cryptocompare.com/data/'\n",
    "            If not provided, the data_cred.cryptocompare_base_url is read from DataCredentials\n",
    "        api_key: str\n",
    "            Cryptocompare api key, e.g. 'dcf13983adf7dfa79a0dfa35adf'\n",
    "            If not provided, the data_cred.cryptocompare_api_key is read from DataCredentials\n",
    "        max_obs_per_call: int, default 2000\n",
    "            Maxiumu number of observations returns per API call.\n",
    "        rate_limit: pd.DataFrame\n",
    "            Number of API calls made and left by frequency.\n",
    "        \"\"\"\n",
    "\n",
    "        DataVendor.__init__(self, source_type, categories, assets, indexes, markets, market_types, fields, frequencies,\n",
    "                            exchanges, base_url, api_key, max_obs_per_call, rate_limit)\n",
    "\n",
    "        # api key\n",
    "        if api_key is None:\n",
    "            raise TypeError(f\"Set your api key. Alternatively, you can use the function \"\n",
    "                            f\"{set_credential.__name__} which uses keyring to store your \"\n",
    "                            f\"api key in {DataCredentials.__name__}.\")\n",
    "        # set assets\n",
    "        if assets is None:\n",
    "            self.assets = self.get_assets_info(as_list=True)\n",
    "        # set indexes\n",
    "        if indexes is None:\n",
    "            self.indexes = self.get_indexes_info(as_list=True)\n",
    "        # set markets\n",
    "        if markets is None:\n",
    "            self.markets = self.get_markets_info(as_list=True)\n",
    "        # set fields\n",
    "        if fields is None:\n",
    "            self.fields = self.get_fields_info(data_type=None)\n",
    "        # set exchanges\n",
    "        if exchanges is None:\n",
    "            self.exchanges = self.get_exchanges_info(as_list=True)\n",
    "        # set rate limit\n",
    "        if rate_limit is None:\n",
    "            self.rate_limit = self.get_rate_limit_info()\n",
    "\n",
    "    def get_assets_info(self, as_list=False) -> Union[pd.DataFrame, list[str]]:\n",
    "        \"\"\"\n",
    "        Gets available assets info.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        as_list: bool, default False\n",
    "            If True, returns available assets as list.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        assets: Union[pd.DataFrame, list[str]]\n",
    "            Info on available assets.\n",
    "        \"\"\"\n",
    "        try:  # try get request\n",
    "            url = data_cred.cryptocompare_base_url + 'all/coinlist'\n",
    "            params = {\n",
    "                'api_key': self.api_key\n",
    "            }\n",
    "            r = requests.get(url, params=params)\n",
    "            assert r.json()['Response'] == 'Success'\n",
    "\n",
    "        except AssertionError as e:\n",
    "            logging.warning(e)\n",
    "            logging.warning(f\"Failed to get asset info.\")\n",
    "\n",
    "        else:\n",
    "            # format response\n",
    "            assets = pd.DataFrame(r.json()['Data']).T\n",
    "            # add index name\n",
    "            assets.index.name = 'ticker'\n",
    "            # asset list\n",
    "            if as_list:\n",
    "                assets = list(assets.index)\n",
    "\n",
    "            return assets\n",
    "\n",
    "    def get_top_market_cap_assets(self, n=100) -> list[str]:\n",
    "        \"\"\"\n",
    "        Gets list of top assets by market cap.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n: int, default 100\n",
    "            Number of assets to return sorted by market cap.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tickers: list[str]\n",
    "            List of tickers for top n coins by market cap.\n",
    "        \"\"\"\n",
    "        # check n value\n",
    "        if n > 100:\n",
    "            raise ValueError(\"Maximum number of assets is 100. Change n parameter and try again.\")\n",
    "\n",
    "        try:  # try get request\n",
    "            url = data_cred.cryptocompare_base_url + 'top/mktcapfull?'\n",
    "            params = {\n",
    "                'limit': n,\n",
    "                'tsym': 'USD',\n",
    "                'api_key': self.api_key\n",
    "            }\n",
    "            r = requests.get(url, params=params)\n",
    "            assert r.json()['Message'] == 'Success'\n",
    "\n",
    "        except AssertionError as e:\n",
    "            logging.warning(e)\n",
    "            logging.warning(f\"Failed to get market cap info.\")\n",
    "\n",
    "        else:\n",
    "            # format response\n",
    "            data = pd.DataFrame(r.json()['Data'])\n",
    "            # create list of tickers\n",
    "            tickers = []\n",
    "            for i in range(0, int(n)):\n",
    "                try:\n",
    "                    tickers.append(data['RAW'][i]['USD']['FROMSYMBOL'])\n",
    "                except:\n",
    "                    logging.warning(\"Failed to pull ticker for coin #{}\\n\".format(str(i)))\n",
    "\n",
    "            return tickers\n",
    "\n",
    "    # get on-chain info\n",
    "    def get_onchain_info(self, as_list=False) -> Union[pd.DataFrame, list[str]]:\n",
    "        \"\"\"\n",
    "        Gets on-chain data info.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        as_list: bool, default False\n",
    "            If True, returns available on-chain data as list.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        onchain: Union[pd.DataFrame, list[str]]\n",
    "            Info on available on-chain data.\n",
    "        \"\"\"\n",
    "        try:  # try get request\n",
    "            url = data_cred.cryptocompare_base_url + 'blockchain/list'\n",
    "            params = {\n",
    "                'api_key': self.api_key\n",
    "            }\n",
    "            r = requests.get(url, params=params)\n",
    "            assert r.json()['Response'] == 'Success'\n",
    "\n",
    "        except AssertionError as e:\n",
    "            logging.warning(e)\n",
    "            logging.warning(f\"Failed to get index info.\")\n",
    "\n",
    "        else:\n",
    "            # format response\n",
    "            onchain = pd.DataFrame(r.json()['Data']).T\n",
    "            # format date\n",
    "            onchain['data_available_from'] = pd.to_datetime(onchain.data_available_from, unit='s')\n",
    "            # add index name\n",
    "            onchain.index.name = 'ticker'\n",
    "            # asset list\n",
    "            if as_list:\n",
    "                onchain = list(onchain.index)\n",
    "\n",
    "            return onchain\n",
    "\n",
    "    # get index info, or list\n",
    "    def get_indexes_info(self, as_list=False) -> Union[pd.DataFrame, list[str]]:\n",
    "        \"\"\"\n",
    "        Gets indexes info.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        as_list: bool, default False\n",
    "            If True, returns available indexes as list.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        indexes: Union[pd.DataFrame, list[str]]\n",
    "            Info on available indexes.\n",
    "        \"\"\"\n",
    "        try:  # try get request\n",
    "            url = data_cred.cryptocompare_base_url + 'index/list'\n",
    "            params = {\n",
    "                'api_key': self.api_key\n",
    "            }\n",
    "            r = requests.get(url, params=params)\n",
    "            assert r.json()['Response'] == 'Success'\n",
    "\n",
    "        except AssertionError as e:\n",
    "            logging.warning(e)\n",
    "            logging.warning(f\"Failed to get index info.\")\n",
    "\n",
    "        else:\n",
    "            # format response\n",
    "            indexes = pd.DataFrame(r.json()['Data']).T\n",
    "            # add index name\n",
    "            indexes.index.name = 'ticker'\n",
    "            # asset list\n",
    "            if as_list:\n",
    "                indexes = list(indexes.index)\n",
    "\n",
    "            return indexes\n",
    "\n",
    "    # get markets info, or list\n",
    "    def get_markets_info(self, as_list=False) -> Union[dict, list[str]]:\n",
    "        \"\"\"\n",
    "        Gets market pairs info.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        as_list: bool, default False\n",
    "            If True, returns available market pairs as list.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        mkts: Union[dict, list[str]]\n",
    "            Info on available market pairs.\n",
    "        \"\"\"\n",
    "        try:  # try get request\n",
    "            url = data_cred.cryptocompare_base_url + 'v2/cccagg/pairs'\n",
    "            params = {\n",
    "                'api_key': self.api_key\n",
    "            }\n",
    "            r = requests.get(url, params=params)\n",
    "            assert r.json()['Response'] == 'Success'\n",
    "\n",
    "        except AssertionError as e:\n",
    "            logging.warning(e)\n",
    "            logging.warning(f\"Failed to get index info.\")\n",
    "\n",
    "        else:\n",
    "            # format response\n",
    "            data_resp = r.json()['Data']\n",
    "            mkts = {}\n",
    "            for asset in data_resp['pairs']:\n",
    "                mkts[asset] = data_resp['pairs'][asset]['tsyms']\n",
    "\n",
    "            # as list\n",
    "            if as_list:\n",
    "                pairs = []\n",
    "                for asset in mkts.keys():\n",
    "                    for quote in mkts[asset]:\n",
    "                        pairs.append(str(asset + quote))\n",
    "                mkts = pairs\n",
    "\n",
    "            return mkts\n",
    "\n",
    "    def get_fields_info(self, data_type: Optional[str]) -> list[str]:\n",
    "        \"\"\"\n",
    "        Gets fields info.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data_type: str, {'market', 'on-chain', 'off-chain'}, default None\n",
    "            Type of data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        fields_list: list[str]\n",
    "            Info on available fields.\n",
    "        \"\"\"\n",
    "\n",
    "        ohlcv_list, onchain_list, social_list = ['open', 'high', 'low', 'close', 'volume'], [], []\n",
    "\n",
    "        try:  # try get request for on-chain data\n",
    "            url = data_cred.cryptocompare_base_url + 'blockchain/latest?fsym=BTC'\n",
    "            params = {\n",
    "                'api_key': self.api_key\n",
    "            }\n",
    "            r = requests.get(url, params=params)\n",
    "            assert r.json()['Response'] == 'Success'\n",
    "            data_resp = r.json()['Data']\n",
    "\n",
    "        except AssertionError as e:\n",
    "            logging.warning(e)\n",
    "            logging.warning(f\"Failed to get on-chain data info.\")\n",
    "\n",
    "        else:\n",
    "            # format onchain resp\n",
    "            for key in list(data_resp):\n",
    "                if key not in ['id', 'time', 'symbol', 'partner_symbol']:\n",
    "                    onchain_list.append(key)\n",
    "\n",
    "        try:  # try get request for social stats\n",
    "            url = data_cred.cryptocompare_base_url + 'social/coin/histo/day'\n",
    "            params = {\n",
    "                'coinId': 1182,\n",
    "                'api_key': self.api_key\n",
    "            }\n",
    "            r = requests.get(url, params=params)\n",
    "            assert r.json()['Response'] == 'Success'\n",
    "            data_resp = r.json()['Data']\n",
    "\n",
    "        except AssertionError as e:\n",
    "            logging.warning(e)\n",
    "            logging.warning(f\"Failed to get on-chain data info.\")\n",
    "\n",
    "        else:\n",
    "            # format social resp\n",
    "            for key in list(data_resp[0]):\n",
    "                if key not in ['id', 'time', 'symbol', 'partner_symbol']:\n",
    "                    social_list.append(key)\n",
    "\n",
    "        # fields list\n",
    "        if data_type == 'market':\n",
    "            fields_list = ohlcv_list\n",
    "        elif data_type == 'on-chain':\n",
    "            fields_list = onchain_list\n",
    "        elif data_type == 'off-chain':\n",
    "            fields_list = social_list\n",
    "        else:\n",
    "            fields_list = ohlcv_list + onchain_list + social_list\n",
    "\n",
    "        return fields_list\n",
    "\n",
    "    def get_exchanges_info(self, as_list=False) -> Union[pd.DataFrame, list[str]]:\n",
    "        \"\"\"\n",
    "        Gets exchanges info.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        as_list: bool, default False\n",
    "            If True, returns available exchanges as list.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        indexes: Union[pd.DataFrame, list[str]]\n",
    "            Info on available exchanges.\n",
    "        \"\"\"\n",
    "        try:  # try get request\n",
    "            url = data_cred.cryptocompare_base_url + 'exchanges/general'\n",
    "            params = {\n",
    "                'api_key': self.api_key\n",
    "            }\n",
    "            r = requests.get(url, params=params)\n",
    "            assert r.json()['Response'] == 'Success'\n",
    "\n",
    "        except AssertionError as e:\n",
    "            logging.warning(e)\n",
    "            logging.warning(f\"Failed to get exchanges info.\")\n",
    "\n",
    "        else:\n",
    "            # format response\n",
    "            exch = pd.DataFrame(r.json()['Data']).T\n",
    "            exch.set_index('Name', inplace=True)\n",
    "            # asset list\n",
    "            if as_list:\n",
    "                exch = list(exch.index)\n",
    "\n",
    "            return exch\n",
    "\n",
    "    def get_news(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Get news articles from various sources.\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        news: pd.DataFrame\n",
    "            News articles from various sources with title, source, body, ...\n",
    "        \"\"\"\n",
    "        try:  # try get request\n",
    "            url = data_cred.cryptocompare_base_url + 'v2/news/?lang=EN'\n",
    "            params = {\n",
    "                'api_key': self.api_key\n",
    "            }\n",
    "            r = requests.get(url, params=params)\n",
    "            assert r.json()['Message'] == 'News list successfully returned'\n",
    "\n",
    "        except AssertionError as e:\n",
    "            logging.warning(e)\n",
    "            logging.warning(f\"Failed to get news articles\")\n",
    "\n",
    "        else:\n",
    "            news = pd.DataFrame(r.json()['Data'])\n",
    "\n",
    "            return news\n",
    "\n",
    "    def get_news_sources(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Gets news sources.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        news_sources: pd.DataFrame\n",
    "            News source with name, language and image.\n",
    "        \"\"\"\n",
    "\n",
    "        try:  # try get request\n",
    "            url = self.base_url + 'news/feeds'\n",
    "            params = {\n",
    "                'api_key': self.api_key\n",
    "            }\n",
    "            r = requests.get(url, params=params)\n",
    "\n",
    "        except AssertionError as e:\n",
    "            logging.warning(e)\n",
    "            logging.warning(f\"Failed to get news articles\")\n",
    "\n",
    "        else:\n",
    "            news_sources = pd.DataFrame(r.json()).set_index('key')\n",
    "\n",
    "            return news_sources\n",
    "\n",
    "    def get_rate_limit_info(self) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Gets rate limit info.\n",
    "\n",
    "        Returns\n",
    "        ------\n",
    "        rate_limit: pd.DataFrame\n",
    "            DataFrame with API calls made and left by period (hour, day, month).\n",
    "        \"\"\"\n",
    "        try:  # try get request\n",
    "            url = 'https://min-api.cryptocompare.com/stats/rate/limit'\n",
    "            params = {\n",
    "                'api_key': self.api_key\n",
    "            }\n",
    "            r = requests.get(url, params=params)\n",
    "            assert r.json()['Response'] == 'Success'\n",
    "\n",
    "        except AssertionError as e:\n",
    "            logging.warning(e)\n",
    "            logging.warning(f\"Failed to get rate limit info.\")\n",
    "\n",
    "        else:\n",
    "            # format response\n",
    "            rate_limit = pd.DataFrame(r.json()['Data'])\n",
    "            # add index name\n",
    "            rate_limit.index.name = 'frequency'\n",
    "\n",
    "            return rate_limit\n",
    "\n",
    "    def fetch_indexes(self, data_req: DataRequest, tidy_data=True) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Submits data request to API for indexes data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data_req: DataRequest\n",
    "            Parameters of data request in CryptoDataPy format.\n",
    "        tidy_data: bool, default True\n",
    "            Wrangles data respponse into the tidy format.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        df: pd.DataFrame\n",
    "            DataFrame with DatetimeIndex and open, high, low and close index values (cols).\n",
    "        \"\"\"\n",
    "        # convert data request parameters to CryptoCompare format\n",
    "        cc_data_req = ConvertParams(data_source='cryptocompare').convert_to_source(data_req)\n",
    "        # empty df to add data\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "        # indexes list\n",
    "        idx_list, tickers = self.indexes, []\n",
    "        # keep only asset tickers\n",
    "        for ticker in cc_data_req['tickers']:\n",
    "            if ticker in idx_list:\n",
    "                tickers.append(ticker)\n",
    "            else:\n",
    "                pass\n",
    "        # raise error if all tickers are assets\n",
    "        if len(tickers) == 0:\n",
    "            raise ValueError(\"Tickers are all assets. Use '.indexes' property to\"\n",
    "                             \" see available indexes.\")\n",
    "\n",
    "        # loop through tickers\n",
    "        for ticker in tickers:\n",
    "\n",
    "            # start and end date\n",
    "            end_date = cc_data_req['end_date']\n",
    "            # create empty ohlc df\n",
    "            df0 = pd.DataFrame()\n",
    "            # set number of attempts and bool for while loop\n",
    "            attempts = 0\n",
    "            # run a while loop to pull ohlcv prices in case the attempt fails\n",
    "            while attempts < cc_data_req['trials']:\n",
    "                try:  # fetch index data\n",
    "                    # get request\n",
    "                    url = self.base_url + \"index/\" + cc_data_req['freq'][:5] + \"/\" + \\\n",
    "                          cc_data_req['freq'][5:]\n",
    "                    params = {\n",
    "                        'indexName': ticker,\n",
    "                        'limit': self.max_obs_per_call,\n",
    "                        'toTs': end_date,\n",
    "                        'api_key': self.api_key\n",
    "                    }\n",
    "                    r = requests.get(url, params=params)\n",
    "                    # resp message\n",
    "                    assert r.json()['Response'] == 'Success'\n",
    "\n",
    "                except AssertionError as e:\n",
    "                    logging.warning(e)\n",
    "                    attempts += 1\n",
    "                    sleep(cc_data_req['pause'])\n",
    "                    logging.warning(f\"Failed to pull data for {ticker} after attempt #{str(attempts)}.\")\n",
    "                    if attempts == 3:\n",
    "                        logging.warning(\n",
    "                            f\"Failed to pull data from Cryptocompare for {ticker} after many attempts\"\n",
    "                            f\" due to following error: {str(r.json()['Message'])}.\")\n",
    "                        break\n",
    "\n",
    "                except Exception as e:\n",
    "                    logging.warning(e)\n",
    "                    logging.warning(\n",
    "                        \"The data's response format has most likely changed.\\n Review Cryptocompares response format\"\n",
    "                        \" and make changes to AlphaFactory's code base.\")\n",
    "                    break\n",
    "\n",
    "                else:\n",
    "                    data = pd.DataFrame(r.json()['Data'])\n",
    "                    # add data to empty df\n",
    "                    df0 = pd.concat([df0, data])\n",
    "                    # check if all data has been extracted\n",
    "                    if len(data) < (self.max_obs_per_call + 1) or data.close[0] == 0 or data.close[0].astype(\n",
    "                            str) == 'nan':\n",
    "                        break\n",
    "                    # reset end date and pause before calling API\n",
    "                    else:\n",
    "                        # change end date\n",
    "                        end_date = data.time[0]\n",
    "                        sleep(cc_data_req['pause'])\n",
    "\n",
    "            # wrangle data resp\n",
    "            if not df0.empty and tidy_data:\n",
    "                df1 = self.wrangle_data_resp(data_req, df0)\n",
    "                # add ticker to df0 and reset index\n",
    "                df1['ticker'] = ticker\n",
    "                df1 = df1.reset_index().set_index(['date', 'ticker']).sort_index()\n",
    "                # concat df and df1\n",
    "                df = pd.concat([df, df1])\n",
    "            elif not df0.empty:\n",
    "                # add ticker to df0 and reset index\n",
    "                df0['ticker'] = ticker\n",
    "                df = pd.concat([df, df0])\n",
    "\n",
    "        return df\n",
    "\n",
    "    def fetch_ohlcv(self, data_req: DataRequest, tidy_data=True) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Submits data request to API for OHLCV data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data_req: DataRequest\n",
    "            Parameters of data request in CryptoDataPy format.\n",
    "        tidy_data: bool, default True\n",
    "            Wrangles data respponse into the tidy format.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        df: pd.DataFrame - MultiIndex\n",
    "            DataFrame with DatetimeIndex (level 0), ticker (level 1), and open, high, low and close prices (cols).\n",
    "        \"\"\"\n",
    "        # convert data request parameters to CryptoCompare format\n",
    "        cc_data_req = ConvertParams(data_source='cryptocompare').convert_to_source(data_req)\n",
    "        # index tickers list\n",
    "        idx_tickers_list = self.get_indexes_info(as_list=True)\n",
    "        # empty df to add data\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "        # indexes list\n",
    "        idx_list, tickers = self.indexes, []\n",
    "        # remove index tickers\n",
    "        for ticker in cc_data_req['tickers']:\n",
    "            if ticker in idx_list:\n",
    "                pass\n",
    "            else:\n",
    "                tickers.append(ticker)\n",
    "        # raise error if all tickers are indexes\n",
    "        if len(tickers) == 0:\n",
    "            raise ValueError('Tickers are all indexes. Try again with get_indexes() method.')\n",
    "\n",
    "        # loop through tickers\n",
    "        for ticker in tickers:\n",
    "\n",
    "            # start and end date\n",
    "            end_date = cc_data_req['end_date']\n",
    "            # create empty ohlc df\n",
    "            df0 = pd.DataFrame()\n",
    "            # set number of attempts and bool for while loop\n",
    "            attempts = 0\n",
    "            # run a while loop to pull ohlcv prices in case the attempt fails\n",
    "            while attempts < cc_data_req['trials']:\n",
    "                try:  # fetch OHLCV data\n",
    "                    # get request\n",
    "                    url = self.base_url + f\"v2/{cc_data_req['freq']}\"\n",
    "                    params = {\n",
    "                        'fsym': ticker,\n",
    "                        'tsym': cc_data_req['quote_ccy'],\n",
    "                        'limit': self.max_obs_per_call,\n",
    "                        'e': cc_data_req['exch'],\n",
    "                        'toTs': end_date,\n",
    "                        'api_key': self.api_key\n",
    "                    }\n",
    "                    r = requests.get(url, params=params)\n",
    "                    # resp message\n",
    "                    assert r.json()['Response'] == 'Success'\n",
    "\n",
    "                except AssertionError as e:\n",
    "                    logging.warning(e)\n",
    "                    attempts += 1\n",
    "                    sleep(cc_data_req['pause'])\n",
    "                    logging.warning(f\"Failed to pull data for {ticker} after attempt #{str(attempts)}.\")\n",
    "                    if attempts == 3:\n",
    "                        logging.warning(\n",
    "                            f\"Failed to pull data from Cryptocompare for {ticker} after many attempts \"\n",
    "                            f\"due to following error: {str(r.json()['Message'])}.\")\n",
    "                        break\n",
    "\n",
    "                except Exception as e:\n",
    "                    logging.warning(e)\n",
    "                    logging.warning(\" The data's response format has most likely changed.\"\n",
    "                                    \" Review Cryptocompare's response format and \"\n",
    "                                    \"make changes to cryptodatapy if necessary.\")\n",
    "                    break\n",
    "\n",
    "                else:\n",
    "                    data = pd.DataFrame(r.json()['Data']['Data'])\n",
    "                    # add data to empty df\n",
    "                    df0 = pd.concat([df0, data])\n",
    "                    # check if all data has been extracted\n",
    "                    if len(data) < (self.max_obs_per_call + 1) or data.close[0] == 0 or data.close[0].astype(\n",
    "                            str) == 'nan':\n",
    "                        break\n",
    "                    # reset end date and pause before calling API\n",
    "                    else:\n",
    "                        # change end date\n",
    "                        end_date = data.time[0]\n",
    "                        sleep(cc_data_req['pause'])\n",
    "\n",
    "            # wrangle data resp\n",
    "            if not df0.empty and tidy_data:\n",
    "                df1 = self.wrangle_data_resp(data_req, df0)\n",
    "                # add ticker to df0 and reset index\n",
    "                df1['ticker'] = ticker\n",
    "                df1 = df1.reset_index().set_index(['date', 'ticker']).sort_index()\n",
    "                # concat df and df1\n",
    "                df = pd.concat([df, df1])\n",
    "            elif not df0.empty:\n",
    "                # add ticker to df0 and reset index\n",
    "                df0['ticker'] = ticker\n",
    "                df = pd.concat([df, df0])\n",
    "\n",
    "        return df\n",
    "\n",
    "    def fetch_onchain(self, data_req: DataRequest, tidy_data=True) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Submits data request to API for on-chain data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data_req: DataRequest\n",
    "            Parameters of data request in CryptoDataPy format.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        df: pd.DataFrame - MultiIndex\n",
    "            DataFrame with DatetimeIndex (level 0), ticker (level 1), and on-chain data (cols).\n",
    "        \"\"\"\n",
    "        # convert data request parameters to CryptoCompare format\n",
    "        cc_data_req = ConvertParams(data_source='cryptocompare').convert_to_source(data_req)\n",
    "        # empty df to add data\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "        # check if frequency daily\n",
    "        if cc_data_req['freq'] != 'histoday':\n",
    "            raise ValueError(f\"On-chain data is only available on a daily frequency.\"\n",
    "                             f\" Change data request frequency to 'd' and try again.\")\n",
    "\n",
    "        # indexes list\n",
    "        idx_list, tickers = self.indexes, []\n",
    "        # remove index tickers\n",
    "        for ticker in cc_data_req['tickers']:\n",
    "            if ticker in idx_list:\n",
    "                pass\n",
    "            else:\n",
    "                tickers.append(ticker)\n",
    "        # raise error if all tickers are indexes\n",
    "        if len(tickers) == 0:\n",
    "            raise ValueError('Tickers are all indexes. Try again with get_indexes() method.')\n",
    "\n",
    "        # loop through tickers\n",
    "        for ticker in tickers:\n",
    "\n",
    "            # start and end date\n",
    "            end_date = cc_data_req['end_date']\n",
    "            # create empty ohlc df\n",
    "            df0 = pd.DataFrame()\n",
    "            # set number of attempts and bool for while loop\n",
    "            attempts = 0\n",
    "            # run a while loop to pull on-chain data in case the attempt fails\n",
    "            while attempts < cc_data_req['trials']:\n",
    "                try:\n",
    "                    # get request\n",
    "                    url = self.base_url + f\"blockchain/histo/day?\"\n",
    "                    params = {\n",
    "                        'fsym': ticker,\n",
    "                        'limit': self.max_obs_per_call,\n",
    "                        'toTs': end_date,\n",
    "                        'api_key': self.api_key\n",
    "                    }\n",
    "                    r = requests.get(url, params=params)\n",
    "                    # resp message\n",
    "                    assert r.json()['Response'] == 'Success'\n",
    "\n",
    "                except AssertionError as e:\n",
    "                    logging.warning(e)\n",
    "                    attempts += 1\n",
    "                    sleep(cc_data_req['pause'])\n",
    "                    logging.warning(f\"Failed to pull data for {ticker} after attempt #{str(attempts)}.\")\n",
    "                    if attempts == 3:\n",
    "                        logging.warning(\n",
    "                            f\"Failed to pull data from Cryptocompare for {ticker} after many attempts \"\n",
    "                            f\"due to following error: {str(r.json()['Message'])}.\")\n",
    "                        break\n",
    "\n",
    "                except Exception as e:\n",
    "                    logging.warning(e)\n",
    "                    logging.warning(\" The data's response format has most likely changed.\"\n",
    "                                    \" Review Cryptocompare's response format and \"\n",
    "                                    \"make changes to cryptodatapy if necessary.\")\n",
    "                    break\n",
    "\n",
    "                else:\n",
    "                    data = pd.DataFrame(r.json()['Data']['Data'])\n",
    "                    # add data to empty df\n",
    "                    df0 = pd.concat([df0, data])\n",
    "                    # check if all data has been extracted\n",
    "                    if len(data) < (self.max_obs_per_call - 1) or all(data.iloc[0] == 0) or all(\n",
    "                            data.iloc[0].astype(str) == 'nan'):\n",
    "                        break\n",
    "                    # reset end date and pause before calling API\n",
    "                    else:\n",
    "                        # change end date\n",
    "                        end_date = data.time[0]\n",
    "                        sleep(cc_data_req['pause'])\n",
    "\n",
    "            # wrangle data resp\n",
    "            if not df0.empty and tidy_data:\n",
    "                df1 = self.wrangle_data_resp(data_req, df0)\n",
    "                # add ticker to df0 and reset index\n",
    "                df1 = df1.reset_index().set_index(['date', 'ticker']).sort_index()\n",
    "                # concat df and df1\n",
    "                df = pd.concat([df, df1])\n",
    "            elif not df0.empty:\n",
    "                # add ticker to df0 and reset index\n",
    "                df = pd.concat([df, df0])\n",
    "\n",
    "        return df\n",
    "\n",
    "    def fetch_social(self, data_req: DataRequest, tidy_data=True) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Submits data request to API for social stats.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data_req: DataRequest\n",
    "            Parameters of data request in CryptoDataPy format.\n",
    "        tidy_data: bool, default True\n",
    "            Wrangles data respponse into the tidy format.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        df: pd.DataFrame - MultiIndex\n",
    "            DataFrame with DatetimeIndex (level 0), ticker (level 1), and social stats (cols).\n",
    "        \"\"\"\n",
    "        # convert data request parameters to CryptoCompare format\n",
    "        cc_data_req = ConvertParams(data_source='cryptocompare').convert_to_source(data_req)\n",
    "        # empty df to add data\n",
    "        df = pd.DataFrame()\n",
    "\n",
    "        # check frequency\n",
    "        if cc_data_req['freq'] != 'histoday' and cc_data_req['freq'] != 'histohour':\n",
    "            raise ValueError(f\"Social stats data is only available on a daily and hourly frequency.\"\n",
    "                             f\" Change data request frequency to 'd' or '1h' and try again.\")\n",
    "\n",
    "        # indexes list\n",
    "        idx_list, tickers = self.indexes, []\n",
    "        # remove index tickers\n",
    "        for ticker in cc_data_req['tickers']:\n",
    "            if ticker in idx_list:\n",
    "                pass\n",
    "            else:\n",
    "                tickers.append(ticker)\n",
    "        # raise error if all tickers are indexes\n",
    "        if len(tickers) == 0:\n",
    "            raise ValueError('Tickers are all indexes. Try again with get_indexes() method.')\n",
    "\n",
    "        # loop through tickers\n",
    "        for ticker in tickers:\n",
    "\n",
    "            # get coinId for ticker\n",
    "            coin_id = int(self.get_assets_info().loc[ticker, 'Id'])\n",
    "            # start and end date\n",
    "            end_date = cc_data_req['end_date']\n",
    "            # create empty ohlc df\n",
    "            df0 = pd.DataFrame()\n",
    "            # set number of attempts and bool for while loop\n",
    "            attempts = 0\n",
    "            # run a while loop to pull on-chain data in case the attempt fails\n",
    "            while attempts < cc_data_req['trials']:\n",
    "                try:\n",
    "                    # get request\n",
    "                    url = self.base_url + \"social/coin/\" + cc_data_req['freq'][:5] + '/' \\\n",
    "                          + cc_data_req['freq'][5:]\n",
    "                    params = {\n",
    "                        'coinId': coin_id,\n",
    "                        'limit': self.max_obs_per_call,\n",
    "                        'toTs': end_date,\n",
    "                        'api_key': self.api_key\n",
    "                    }\n",
    "                    r = requests.get(url, params=params)\n",
    "                    # resp message\n",
    "                    assert r.json()['Response'] == 'Success'\n",
    "\n",
    "                except AssertionError as e:\n",
    "                    attempts += 1\n",
    "                    sleep(cc_data_req['pause'])\n",
    "                    logging.warning(e)\n",
    "                    logging.warning(f\"Failed to pull data for {ticker} after attempt #{str(attempts)}.\")\n",
    "                    if attempts == 3:\n",
    "                        logging.warning(\n",
    "                            f\"Failed to pull data from Cryptocompare for {ticker} after many attempts \"\n",
    "                            f\"due to following error: {str(r.json()['Message'])}.\")\n",
    "                        break\n",
    "\n",
    "                except Exception as e:\n",
    "                    logging.warning(e)\n",
    "                    logging.warning(\" The data's response format has most likely changed.\"\n",
    "                                    \" Review Cryptocompare's response format and \"\n",
    "                                    \"make changes to cryptodatapy if necessary.\")\n",
    "                    break\n",
    "\n",
    "                else:\n",
    "                    data = pd.DataFrame(r.json()['Data'])\n",
    "                    # add data to empty df\n",
    "                    df0 = pd.concat([df0, data])\n",
    "                    # check if all data has been extracted\n",
    "                    if len(data) < (self.max_obs_per_call + 1) or all(data.drop(columns=['time']).iloc[0] == 0) or all(\n",
    "                            data.drop(columns=['time']).iloc[0].astype(str) == 'nan'):\n",
    "                        break\n",
    "                    # reset end date and pause before calling API\n",
    "                    else:\n",
    "                        # change end date\n",
    "                        end_date = data.time[0]\n",
    "                        sleep(cc_data_req['pause'])\n",
    "\n",
    "            # wrangle data resp\n",
    "            if not df0.empty and tidy_data:\n",
    "                df1 = self.wrangle_data_resp(data_req, df0)\n",
    "                # add ticker to df0 and reset index\n",
    "                df1['ticker'] = ticker\n",
    "                df1 = df1.reset_index().set_index(['date', 'ticker']).sort_index()\n",
    "                # concat df and df1\n",
    "                df = pd.concat([df, df1])\n",
    "            elif not df0.empty:\n",
    "                # add ticker to df0 and reset index\n",
    "                df0['ticker'] = ticker\n",
    "                df = pd.concat([df, df0])\n",
    "\n",
    "        return df\n",
    "\n",
    "    def fetch_data(self, data_req: DataRequest) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Fetches either OHLCV, on-chain or social stats data.\n",
    "\n",
    "        Parameters\n",
    "        data_req: DataRequest\n",
    "            Parameters of data request in CryptoDataPy format.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        df: pd.DataFrame - MultiIndex\n",
    "            DataFrame with DatetimeIndex (level 0), ticker (level 1), and OHLCV, on-chain and/or social data (cols).\n",
    "        \"\"\"\n",
    "        # convert data request parameters to CryptoCompare format\n",
    "        cc_data_req = ConvertParams(data_source='cryptocompare').convert_to_source(data_req)\n",
    "\n",
    "        # check if fields available\n",
    "        fields_list = self.get_fields_info(data_type=None)\n",
    "        if not all(i in fields_list for i in cc_data_req['fields']):\n",
    "            raise ValueError(\n",
    "                'Fields are not available. Check available fields with get_fields_info() method and try again.')\n",
    "\n",
    "        # fields list\n",
    "        ohlcv_list = self.get_fields_info(data_type='market')\n",
    "        onchain_list = self.get_fields_info(data_type='on-chain')\n",
    "        offchain_list = self.get_fields_info(data_type='off-chain')\n",
    "\n",
    "        # create index tickers list and empty df\n",
    "        idx_tickers_list, df = self.indexes, pd.DataFrame()\n",
    "\n",
    "        # fetch indexes data\n",
    "        if any(i in idx_tickers_list for i in cc_data_req['tickers']) and \\\n",
    "                any(i in ohlcv_list for i in cc_data_req['fields']):\n",
    "            try:\n",
    "                df0 = self.fetch_indexes(data_req)\n",
    "            except Exception as e:\n",
    "                logging.warning(e)\n",
    "            else:\n",
    "                df = pd.concat([df, df0])\n",
    "\n",
    "        # fetch OHLCV data\n",
    "        if any(i in ohlcv_list for i in cc_data_req['fields']):\n",
    "            try:\n",
    "                df1 = self.fetch_ohlcv(data_req)\n",
    "            except Exception as e:\n",
    "                logging.warning(e)\n",
    "            else:\n",
    "                df = pd.concat([df, df1])\n",
    "\n",
    "        # fetch on-chain data\n",
    "        if any(i in onchain_list for i in cc_data_req['fields']):\n",
    "            try:\n",
    "                df2 = self.fetch_onchain(data_req)\n",
    "            except Exception as e:\n",
    "                logging.warning(e)\n",
    "            else:\n",
    "                df = pd.concat([df, df2], axis=1)\n",
    "\n",
    "        # fetch social stats data\n",
    "        if any(i in offchain_list for i in cc_data_req['fields']):\n",
    "            try:\n",
    "                df3 = self.fetch_social(data_req)\n",
    "            except Exception as e:\n",
    "                logging.warning(e)\n",
    "            else:\n",
    "                df = pd.concat([df, df3], axis=1)\n",
    "\n",
    "        # check if df empty\n",
    "        if df.empty:\n",
    "            raise Exception('No data returned. Check data request parameters and try again.')\n",
    "\n",
    "        # filter df for desired fields and sort index by date\n",
    "        fields = [field for field in data_req.fields if field in df.columns ]\n",
    "        df = df.loc[:, fields]\n",
    "\n",
    "        return df.sort_index()\n",
    "\n",
    "    @staticmethod\n",
    "    def wrangle_data_resp(data_req: DataRequest, data_resp: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Wrangles OHLCV data response.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data_req: DataRequest\n",
    "            Parameters of data request in CryptoDataPy format.\n",
    "        data_resp: pd.DataFrame\n",
    "            Data response from GET request.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        df: pd.DataFrame\n",
    "            Wrangled OHLCV dataframe in tidy format.\n",
    "        \"\"\"\n",
    "        # convert cols to cryptodatapy format\n",
    "        df = ConvertParams(data_source='cryptocompare').convert_fields_to_lib(data_resp)\n",
    "        # format col order\n",
    "        if 'volume' in df.columns:  # ohlcv data resp\n",
    "            df = df.loc[:, ['date', 'open', 'high', 'low', 'close', 'volume']]\n",
    "        elif 'volume' not in df.columns and 'close' in df.columns:  # indexes data resp\n",
    "            df = df.loc[:, ['date', 'open', 'high', 'low', 'close']]\n",
    "\n",
    "        # convert date and set datetimeindex\n",
    "        df['date'] = pd.to_datetime(df['date'], unit='s')\n",
    "        df = df.set_index('date').sort_index()\n",
    "\n",
    "        # filter for desired start to end date\n",
    "        if data_req.start_date is not None:\n",
    "            df = df[(df.index >= data_req.start_date)]\n",
    "        if data_req.end_date is not None:\n",
    "            df = df[(df.index <= data_req.end_date)]\n",
    "\n",
    "        # resample freq\n",
    "        df = df.resample(data_req.freq).last()\n",
    "\n",
    "        # remove bad data\n",
    "        df = df[df != 0].dropna(how='all')  # 0 values\n",
    "        df = df[~df.index.duplicated()]  # duplicate rows\n",
    "        df.dropna(how='all', inplace=True)  # remove entire row NaNs\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1e170e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = CryptoCompare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "45d29313",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_req = DataRequest(tickers=['btc', 'eth', 'mvda'], fields=['close', 'add_act', 'tx', 'followers'], freq='2h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ea0a623f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:On-chain data is only available on a daily frequency. Change data request frequency to 'd' and try again.\n"
     ]
    }
   ],
   "source": [
    "df = cc.fetch_data(data_req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "280dca6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>followers</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-08-29 16:00:00</th>\n",
       "      <th>BTC</th>\n",
       "      <td>0.064</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-08-29 18:00:00</th>\n",
       "      <th>BTC</th>\n",
       "      <td>0.064</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-08-29 20:00:00</th>\n",
       "      <th>BTC</th>\n",
       "      <td>0.064</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-08-29 22:00:00</th>\n",
       "      <th>BTC</th>\n",
       "      <td>0.064</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-08-30 00:00:00</th>\n",
       "      <th>BTC</th>\n",
       "      <td>0.064</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2022-07-10 20:00:00</th>\n",
       "      <th>ETH</th>\n",
       "      <td>1176.860</td>\n",
       "      <td>90944.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MVDA</th>\n",
       "      <td>6101.150</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">2022-07-10 22:00:00</th>\n",
       "      <th>BTC</th>\n",
       "      <td>20846.530</td>\n",
       "      <td>105327.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ETH</th>\n",
       "      <td>1167.310</td>\n",
       "      <td>90944.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MVDA</th>\n",
       "      <td>6061.840</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104150 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                close  followers\n",
       "date                ticker                      \n",
       "2010-08-29 16:00:00 BTC         0.064        NaN\n",
       "2010-08-29 18:00:00 BTC         0.064        NaN\n",
       "2010-08-29 20:00:00 BTC         0.064        NaN\n",
       "2010-08-29 22:00:00 BTC         0.064        NaN\n",
       "2010-08-30 00:00:00 BTC         0.064        NaN\n",
       "...                               ...        ...\n",
       "2022-07-10 20:00:00 ETH      1176.860    90944.0\n",
       "                    MVDA     6101.150        NaN\n",
       "2022-07-10 22:00:00 BTC     20846.530   105327.0\n",
       "                    ETH      1167.310    90944.0\n",
       "                    MVDA     6061.840        NaN\n",
       "\n",
       "[104150 rows x 2 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d116b91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fbd3fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3b6fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cryptodatapy",
   "language": "python",
   "name": "cryptodatapy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
