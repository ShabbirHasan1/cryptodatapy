{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a197b250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from time import sleep\n",
    "from importlib import resources\n",
    "from typing import Optional, Union, Any\n",
    "from cryptodatapy.util.datacredentials import DataCredentials, set_credential\n",
    "from cryptodatapy.util.convertparams import ConvertParams\n",
    "from cryptodatapy.data_vendors.datavendor import DataVendor\n",
    "from cryptodatapy.data_requests.datarequest import DataRequest\n",
    "import nasdaqdatalink as nasdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68ddcb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data credentials\n",
    "data_cred = DataCredentials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "316b5e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NasdaqDataLink(DataVendor):\n",
    "    \"\"\"\n",
    "    Retrieves data from Nasdaq Data Link (formerly Quandl) API.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            source_type: str = 'data_vendor',\n",
    "            categories: list[str] = ['rates', 'credit', 'macro'],\n",
    "            vendors: dict[str, str] = None,\n",
    "            assets: list[str] = None,\n",
    "            indexes: list[str] = None,\n",
    "            markets: list[str] = None,\n",
    "            market_types: list[str] = ['spot'],\n",
    "            fields: dict[str, list[str]] = None,\n",
    "            frequencies: dict[str, list[str]] = {'rates': ['d', 'w', 'm', 'q', 'y'],\n",
    "                                                 'credit': ['d', 'w', 'm', 'q', 'y'],\n",
    "                                                'macro': ['m', 'q', 'y']},\n",
    "            exchanges: list[str] = None,\n",
    "            base_url: str = None,\n",
    "            api_key: str = data_cred.quandl_api_key,\n",
    "            max_obs_per_call: int = None,\n",
    "            rate_limit: str = data_cred.ndl_api_rate_limit\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        source_type: string, {'data_vendor', 'exchange', 'library', 'on-chain', 'web'}\n",
    "            Type of data source, e.g. 'data_vendor', 'exchange', etc.\n",
    "        categories: list, {'crypto', 'fx', 'rates', 'eqty', 'commodities', 'credit', 'macro', 'alt'}\n",
    "            List of available categories, e.g. ['crypto', 'fx', 'alt']\n",
    "        vendors: list\n",
    "            List of available data vendors, e.g. ['IMF Cross Country Macroeconomic Statistics']\n",
    "        assets: list\n",
    "            List of available assets, e.g. ['btc', 'eth']\n",
    "        indexes: list\n",
    "            List of available indexes, e.g. ['mvda', 'bvin']\n",
    "        markets: list\n",
    "            List of available markets as asset/quote currency pairs, e.g. ['btcusdt', 'ethbtc']\n",
    "        market_types: list\n",
    "            List of available market types/contracts, e.g. [spot', 'perpetual_future', 'future', 'option']\n",
    "        fields: list\n",
    "            List of available fields, e.g. ['open', 'high', 'low', 'close', 'volume']\n",
    "        frequencies: list\n",
    "            List of available frequencies, e.g. ['tick', '1min', '5min', '10min', '20min', '30min', '1h', '2h', '4h',\n",
    "            '8h', 'd', 'w', 'm']\n",
    "        exchanges: list\n",
    "            List of available exchanges, e.g. ['Binance', 'Coinbase', 'Kraken', 'FTX']\n",
    "        base_url: str\n",
    "            Cryptocompare base url used in GET requests, e.g. 'https://min-api.cryptocompare.com/data/'\n",
    "            If not provided, default is set to cryptocompare_base_url stored in DataCredentials\n",
    "        api_key: str\n",
    "            Cryptocompare api key, e.g. 'dcf13983adf7dfa79a0dfa35adf'\n",
    "            If not provided, default is set to cryptocompare_api_key stored in DataCredentials\n",
    "        max_obs_per_call: int\n",
    "            Maximum number of observations returns per API call.\n",
    "            If not provided, default is set to cryptocompare_api_limit storeed in DataCredentials\n",
    "        rate_limit: pd.DataFrame\n",
    "            Number of API calls made and left by frequency.\n",
    "        \"\"\"\n",
    "\n",
    "        DataVendor.__init__(self, source_type, categories, assets, indexes, markets, market_types, fields, frequencies,\n",
    "                            exchanges, base_url, api_key, max_obs_per_call, rate_limit)\n",
    "        \n",
    "        self.vendors = vendors  # data vendors\n",
    "\n",
    "        # set vendors\n",
    "        if vendors is None:\n",
    "            self.vendors = self.get_vendors_info(vendor=None)\n",
    "        # set fields\n",
    "        if fields is None:\n",
    "            self.fields = self.get_fields_info()\n",
    "\n",
    "    def get_vendors_info(self, vendor=None) -> Union[pd.DataFrame, dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        vendor: str, default None\n",
    "            Name of data vendor.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        vendors: Dataframe or dict\n",
    "            Info on available data vendors, by name.\n",
    "        \"\"\"\n",
    "        # TODO: add additional vendors which can be useful for analysis of digital assets\n",
    "\n",
    "        # vendor-code pairs for databases\n",
    "        vendors = {\n",
    "\n",
    "            'Federal Reserve Economic Data': 'FRED',\n",
    "            'US Federal Reserve Data Releases': 'FED',\n",
    "            'US Treasury': 'USTREASURY',\n",
    "            'European Central Bank': 'ECB',\n",
    "            'Bank of England Official Statistics': 'BOE',\n",
    "            'Corporate Bond Yield Rates': 'ML',\n",
    "            'IMF Cross Country Macroeconomic Statistics': 'ODA',\n",
    "            'Organisation for Economic Co-operation and Development': 'OECD'\n",
    "        }\n",
    "        \n",
    "        # get vendor metadata \n",
    "        if vendor is not None:\n",
    "            code = vendors[vendor]\n",
    "            url = f\"https://data.nasdaq.com/api/v3/databases/{code}.json?api_key=\" + self.api_key\n",
    "            r = requests.get(url)\n",
    "            vendors = pd.DataFrame(r.json())\n",
    "            \n",
    "        return vendors\n",
    "            \n",
    "    @staticmethod\n",
    "    def get_assets_info():\n",
    "        \"\"\"\n",
    "        Gets available assets info.\n",
    "        \"\"\"\n",
    "        print(f\"See search page to find available assets: {data_cred.ndl_search_url} \")\n",
    "\n",
    "    @staticmethod\n",
    "    def get_indexes_info():\n",
    "        \"\"\"\n",
    "        Gets available indexes info.     \n",
    "        \"\"\"\n",
    "        print(f\"See search page to find available indexes: {data_cred.ndl_search_url} \")\n",
    "\n",
    "    @staticmethod\n",
    "    def get_markets_info():\n",
    "        \"\"\"\n",
    "        Gets market pairs info.\n",
    "        \"\"\"\n",
    "        print(f\"See search page to find available markets: {data_cred.ndl_search_url} \")\n",
    "\n",
    "    def get_fields_info(self, data_type: Optional[str] = 'off-chain', cat=None) -> dict[str, list[str]]:\n",
    "        \"\"\"\n",
    "        Gets fields info.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data_type: str, {'market', 'on-chain', 'off-chain'}, default 'market'\n",
    "            Type of data.\n",
    "        cat: str, {'crypto', 'eqty', 'fx', 'rates', 'cmdty', 'macro'}, default None\n",
    "            Asset class or time series category.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        fields_list: dict\n",
    "            Info on available fields, by category.\n",
    "        \"\"\"\n",
    "        if data_type == 'on-chain':\n",
    "            raise Exception(\"No on-chain data available. Nasdaq data link only provides market and macro data.\")\n",
    "            \n",
    "        # list of fields \n",
    "        rates_fields_list = ['close']\n",
    "        credit_fields_list = ['close']\n",
    "        macro_fields_list = ['actual']\n",
    "\n",
    "        # fields dict\n",
    "        fields = {\n",
    "                  'rates': rates_fields_list,\n",
    "                  'credit': credit_fields_list,\n",
    "                  'macro': macro_fields_list,\n",
    "                  }\n",
    "        \n",
    "        # fields obj                \n",
    "        if cat is not None:\n",
    "            fields = fields[cat]\n",
    "                        \n",
    "        return fields\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_exchanges_info():\n",
    "        \"\"\"\n",
    "        Gets exchanges info.\n",
    "        \"\"\"\n",
    "        print(f\"See search page to find available exchanges: {data_cred.ndl_search_url} \")\n",
    "\n",
    "    def get_rate_limit_info(self):\n",
    "        \"\"\"\n",
    "        Gets rate limit info.\n",
    "        \"\"\"\n",
    "        print(f\"See rate limit info: {self.rate_limit}\")\n",
    "    \n",
    "    def get_data(self, data_req: DataRequest) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Submits data request to Nasdaq Data Link API for data.\n",
    "        \"\"\"\n",
    "        # convert data request parameters to InvestPy format\n",
    "        ip_data_req = ConvertParams(data_source='ndl').convert_to_source(data_req)\n",
    "        with resources.path('cryptodatapy.conf', 'tickers.csv') as f:\n",
    "            tickers_path = f\n",
    "        tickers = pd.read_csv(tickers_path, index_col=0, encoding='latin1').index.to_list()\n",
    "        \n",
    "        # check cat\n",
    "        if data_req.cat not in self.categories:\n",
    "            raise ValueError(f\"Invalid category. Valid categories are: {self.categories}.\")\n",
    "            \n",
    "        # check freq\n",
    "        if data_req.freq not in self.frequencies[data_req.cat]:\n",
    "            raise ValueError(f\"Invalid data frequency. Valid data frequencies are: {self.frequencies}.\")\n",
    "            \n",
    "        # check fields\n",
    "        if not any(field in self.fields[data_req.cat] for field in data_req.fields):\n",
    "            raise ValueError(\"Invalid fields. See '.fields' property for available fields.\")\n",
    "        \n",
    "        # emtpy df\n",
    "        df = pd.DataFrame()\n",
    "        \n",
    "        # loop through tickers, countries\n",
    "        for dr_ticker, ndl_ticker in zip(data_req.tickers, ndl_data_req['tickers']):\n",
    "        \n",
    "            # get data from ndl\n",
    "            df0 = nasdl.get(ticker)\n",
    "            \n",
    "            # wrangle data resp\n",
    "            if not df0.empty:\n",
    "                # wrangle data resp\n",
    "                df1 = self.wrangle_data_resp(data_req, df0)\n",
    "                # add ticker to index\n",
    "                df1['ticker'] = dr_ticker\n",
    "                df1.set_index(['ticker'], append=True, inplace=True)\n",
    "                # stack ticker dfs\n",
    "                df = pd.concat([df, df1])  \n",
    "            \n",
    "        # check if df empty\n",
    "        if df.empty:\n",
    "            raise Exception('No data returned. Check data request parameters and try again.')\n",
    "\n",
    "        # filter df for desired fields and typecast\n",
    "        fields = [field for field in data_req.fields if field in df.columns ]\n",
    "        df = df.loc[:, fields]\n",
    "        # type conversion\n",
    "        df = ConvertParams().convert_dtypes(df)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def wrangle_data_resp(data_req: DataRequest, data_resp: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Wrangles data response.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        data_req: DataRequest\n",
    "            Parameters of data request in CryptoDataPy format.\n",
    "        data_resp: pd.DataFrame\n",
    "            Data response from GET request.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        df: pd.DataFrame\n",
    "            Wrangled dataframe in tidy format.\n",
    "        \"\"\"\n",
    "        if data_req.cat != 'macro':\n",
    "            # reset index\n",
    "            data_resp = data_resp.reset_index()\n",
    "        else:\n",
    "            # parse date and time to create datetime\n",
    "            data_resp['date'] = pd.to_datetime(data_resp.date + data_resp.time, format=\"%d/%m/%Y%H:%M\")\n",
    "            # replace missing vals and compute surprise val\n",
    "            data_resp.forecast = np.where(np.nan, data_resp.previous, data_resp.forecast)  \n",
    "            \n",
    "        # convert cols to cryptodatapy format\n",
    "        df = ConvertParams(data_source='investpy').convert_fields_to_lib(data_req, data_resp)\n",
    "        # set index\n",
    "        df.set_index('date', inplace=True)\n",
    "        # str and resample to 5min freq for econ releases\n",
    "        if data_req.cat == 'macro':\n",
    "            df = df.replace('%', '', regex=True)  # remove % str\n",
    "            # merge with empty datetimeindex df and ffill missing vals\n",
    "            idx_df = pd.DataFrame(index=pd.date_range(start=df.index[0], end=datetime.utcnow(), freq='5min'))\n",
    "            idx_df.index.name = 'date'\n",
    "            df = idx_df.merge(df, how='outer', left_index=True, right_index=True).astype(float).ffill()\n",
    "            df['surprise'] = df.actual - df.expected\n",
    "        \n",
    "        # resample freq\n",
    "        df = df.resample(data_req.freq).last()\n",
    "        \n",
    "        # filter bad data\n",
    "        if 'surprise' in df.columns:\n",
    "            df = pd.concat([df[df.columns.drop('surprise')][df != 0], df.loc[:,['surprise']]], axis=1)\n",
    "        else:\n",
    "            df = df[df != 0]  # 0 values\n",
    "        df = df[~df.index.duplicated()]  # duplicate rows\n",
    "        df = df.dropna(how='all').dropna(how='all', axis=1) # entire row or col NaNs\n",
    "\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32a70e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndl = NasdaqDataLink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "593dcc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "See rate limit info: https://help.data.nasdaq.com/article/490-is-there-a-rate-limit-or-speed-limit-for-api-usage\n"
     ]
    }
   ],
   "source": [
    "ndl.get_rate_limit_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78303cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5f68be",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndl.get_assets_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7816230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_req = DataRequest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67755c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ndl_data_req = ConvertParams(data_source='ndl').convert_to_source(data_req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8350404c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ndl_data_req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2810dc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndl.vendors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0295c6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = nasdl.get(\"ODA/USA_PPPSH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "016615ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['1980-12-31', '1981-12-31', '1982-12-31', '1983-12-31',\n",
       "               '1984-12-31', '1985-12-31', '1986-12-31', '1987-12-31',\n",
       "               '1988-12-31', '1989-12-31', '1990-12-31', '1991-12-31',\n",
       "               '1992-12-31', '1993-12-31', '1994-12-31', '1995-12-31',\n",
       "               '1996-12-31', '1997-12-31', '1998-12-31', '1999-12-31',\n",
       "               '2000-12-31', '2001-12-31', '2002-12-31', '2003-12-31',\n",
       "               '2004-12-31', '2005-12-31', '2006-12-31', '2007-12-31',\n",
       "               '2008-12-31', '2009-12-31', '2010-12-31', '2011-12-31',\n",
       "               '2012-12-31', '2013-12-31', '2014-12-31', '2015-12-31',\n",
       "               '2016-12-31', '2017-12-31', '2018-12-31', '2019-12-31',\n",
       "               '2020-12-31', '2021-12-31', '2022-12-31', '2023-12-31',\n",
       "               '2024-12-31'],\n",
       "              dtype='datetime64[ns]', name='Date', freq=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4f7047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe1431b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f873410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a072e7e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cryptodatapy",
   "language": "python",
   "name": "cryptodatapy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
